dataset:
  dir:
    train: "/raid/candi/Yunguan/DeepReg/neuroimaging/preprocessed" # required
    valid:
    test:
  format: "nifti"
  type: "unpaired" # paired / unpaired / grouped
  labeled: false # whether to use the labels if available, "true" or "false"
  image_shape: [192, 224, 192]

train:
  # define neural network structure
  method: "ddf" # options include "ddf", "dvf", "conditional"
  backbone:
    name: "vm_balakrishnan_2019" # options include "local", "unet" and "global"
    num_channel_initial: 16 # number of initial channel in local net, controls the size of the network
    depth: 4
    concat_skip: true
    encode_num_channels: [16, 32, 32, 32, 32]
    decode_num_channels: [32, 32, 32, 32, 32]

  # define the loss function for training
  loss:
    image:
      name: "lncc" # other options include "lncc", "ssd" and "gmi", for local normalised cross correlation,
      weight: 1.0
    label:
      weight: 0.0
      name: "dice" # options include "dice", "cross-entropy", "mean-squared", "generalised_dice" and "jaccard"
    regularization:
      weight: 1.0 # weight of regularization loss
      name: "gradient" # options include "bending", "gradient"

  # define the optimizer
  optimizer:
    name: "adam" # options include "adam", "sgd" and "rms"
    adam:
      learning_rate: 1.0e-4

  # define the hyper-parameters for preprocessing
  preprocess:
    data_augmentation:
      name: "affine"
    batch_size: 2
    shuffle_buffer_num_batch: 1 # shuffle_buffer_size = batch_size * shuffle_buffer_num_batch

  # other training hyper-parameters
  epochs: 2 # number of training epochs
  save_period: 2 # the model will be saved every `save_period` epochs.
  update_freq: 50
